{
  "Abysz LAB": "Abysz LAB",
  "Main": "メイン",
  "LAB Tools": "LABツール",
  "Guide": "ガイド",
  "Abysz LAB 0.1.9 Temporal coherence tools": "Abysz LAB 0.1.9 時間的な一貫性ツール",
  "DFI Render": "DFIレンダー (Differential frame interpolation - 差分フレーム補完)",
  "Original frames folder": "オリジナルフレームフォルダ",
  "Generated frames folder": "生成したフレームフォルダ",
  "Output folder": "出力先フォルダ",
  "Info": "情報",
  "The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.": "新しいアルゴリズムは、各フレームのパラメータを選択するために、DFIの許容範囲に適応します。重要：アルゴリズムは、デフリックとコラプションのバランスを保つように最適化されており、低ノイズ化でStableDiffusionを使用すると、得られた安定性を維持しながら失われたディテールを再構築することが容易になる。",
  "Source denoise:": "ソースデノイズ：",
  "A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.": "ノイズの多いソースは、スキャンの精度を妨げる可能性があります。この場合、ノイズは減少しますが、ディテールも減少します。しかし、これはオリジナルには影響しませんし、DFIの許容範囲を狭めることでバランスを取る必要があるかもしれませんが、時には平坦な画像もプロセス上悪いことではありません。",
  "(This is a demanding algorithm)": "(これは要求の高いアルゴリズムです)",
  "DFI Tolerance:": "許容範囲:",
  "Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.": "スキャンの移動許容度を決定します。許容範囲が低いと、静止している部分の小さな変化も検知してしまいます。高い値では、より少ない動きを検出します。理想的には、重要な動きを検出し、静的な部分や無駄な部分をスキップして、それらのフリックを減らすことです。",
  "This parameter commands the new dynamic algorithm.": "このパラメータは、新しいダイナミックアルゴリズムを指令します。",
  "DFI Expand:": "DFI Expand:",
  "DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.": "DFIエクスパンドは、DFIで検出された部分のエッジを太くする。注）DFIトレランスは、検出された動きの量を修正します。これは、結果の大小にかかわらず、その結果にのみ影響します。補完的なパラメーターです。0=オフ。",
  "Source Denoise": "ソースデノイズ：",
  "DFI Tolerance": "許容範囲",
  "DFI Expand": "DFI Expand",
  "Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.": "ここでは、それらのパラメータに対するモーションマップの例を確認することができます。例えば、不要な粒状性を検出した場合、ノイズを調整するのに有効です。あくまで2フレーム間の動きであることを意識してください。",
  "The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).": "黒は基本的にそれが処理しないものです(それは動きを維持するためにそれを介してさせます)。 白色はフレーム補間の中で安定しようとしています ここでは、手動のスムーズな動作(高度なセクション) をテストすることもできます。",
  "Preview DFI Map": "マッププレビュー",
  "Preview amount. 0 = Quick shoot": "Preview amount. 0 = Quick shoot",
  "Advanced": "高度な設定",
  "Inter Denoise:": "Inter Denoise:",
  "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.": "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.",
  "Inter Blur:": "Inter Blur:",
  "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.": "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.",
  "Corruption Refresh:": "Corruption Refresh:",
  "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.": "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.",
  "Corruption Preserve:": "Corruption Preserve:",
  "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.": "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.",
  "Smooth:": "Smooth:",
  "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.": "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.",
  "Inter Denoise": "Inter Denoise",
  "Inter Denoise Size": "Inter Denoise Size",
  "Inter Denoise FPD": "Inter Denoise FPD",
  "Inter Blur": "Inter Blur",
  "The new dynamic algorithm will handle these parameters. Activate them only for manual control.": "The new dynamic algorithm will handle these parameters. Activate them only for manual control.",
  "Corruption Refresh (Lower = Faster)": "Corruption Refresh (Lower = Faster)",
  "Corruption Preserve": "Corruption Preserve",
  "Smooth": "Smooth",
  "Frames to render. 0=ALL": "Frames to render. 0=ALL",
  "Run DFI": "Run DFI",
  "Status": "ステータス",
  "Show output folder video": "Show output folder video",
  "|": "|",
  "Deflickers Playground": "Deflickers Playground",
  "Frames folder": "Frames folder",
  "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.": "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.",
  "Blend:": "Blend:",
  "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.": "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.",
  "Overlay:": "Overlay:",
  "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.": "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.",
  "Normalize:": "Normalize:",
  "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.": "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.",
  "BLEND (0=Off)": "BLEND (0=Off)",
  "OVERLAY (0=Off)": "OVERLAY (0=Off)",
  "NORMALIZE (0=Off))": "NORMALIZE (0=Off))",
  "Deflickers": "Deflickers",
  "Style Fuse": "Style Fuse",
  "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.": "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.",
  "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.": "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.",
  "Style frames": "Style frames",
  "Video frames": "Video frames",
  "Fuse Strength": "Fuse Strength",
  "Fuse": "Fuse",
  "Video extract": "Video extract",
  "Video path": "Video path",
  "Fps. 0=Original": "Fps. 0=Original",
  "Extract": "Extract",
  "What DFI does?": "What DFI does?",
  "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext": "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext",
  "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.": "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.",
  "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.": "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.",
  "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.": "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.",
  "Usage strategies": "Usage strategies",
  "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.": "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.",
  "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.": "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.",
  "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.": "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.",
  "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.": "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.",
  "Abysz-LAB-Ext": "Abysz-LAB-Ext",
  "https://github.com/AbyszOne/Abysz-LAB-Ext": "https://github.com/AbyszOne/Abysz-LAB-Ext",
  "The RAW frames you have used as base for IA generation.": "The RAW frames you have used as base for IA generation.",
  "The frames of AI generated video": "The frames of AI generated video",
  "Remember that each generation overwrites previous frames in the same folder.": "Remember that each generation overwrites previous frames in the same folder.",
  "STAND BY...": "STAND BY...",
  "Frames to process": "Frames to process",
  "Processed frames": "Processed frames",
  "Style to fuse": "Style to fuse",
  "Remember to use same fps as generated video for DFI": "Remember to use same fps as generated video for DFI"
}
