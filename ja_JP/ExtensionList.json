{
  "Aesthetic Gradients": "Aesthetic Gradients",
  "Allows training an embedding from one or few pictures, specifically meant for applying styles. Also, allows use of these specific embeddings to generated images.": "少数の画像を埋め込む学習ができます。これは画風を付与することになります。そして、それらの埋め込んだものを使って画像を生成することもできます。",
  "Dreambooth": "Dreambooth",
  "Dreambooth training based on Shivam Shiaro's repo, optimized for lower-VRAM GPUs.": "Dreambooth trainingはShivam Shiaro氏のリポジトリを元に、低VRAMのGPU向けに最適化されています。",
  "training-picker": "training-picker",
  "Adds a tab to the webui that allows the user to automatically extract keyframes from video, and manually extract 512x512 crops of those frames for use in model training.": "動画からキーフレームを自動的に抽出できるタブを webui に追加します。 その後、512x512のクロップを手動で抽出してモデル学習に使用します。",
  "Dataset Tag Editor": "Dataset Tag Editor",
  "Feature-rich UI tab that allows image viewing, search-filtering and editing.": "画像の表示、検索フィルタリング、編集を可能にする機能豊富なUIタブ。",
  "DreamArtist": "DreamArtist",
  "Towards Controllable One-Shot Text-to-Image Generation via Contrastive Prompt-Tuning.": "コントラストプロンプトチューニングを介して、制御可能なワンショットテキストから画像への生成に向けて。",
  "WD 1.4 Tagger": "WD 1.4 Tagger",
  "Interrogates single or multiple image files using various alternative models, similar to deepdanbooru interrogate.": "Deepdanbooru interrogateと同様に、様々な代替モデルを使用して単一または複数の画像ファイルを問い合わせる。",
  "Hypernetwork-Monkeypatch-Extension": "Hypernetwork-Monkeypatch-Extension",
  "Extension that provides additional training features for hypernetwork training. Also supports using multiple hypernetworks for inference.": "Hypernetworkのための追加学習機能を提供する拡張機能です。また、推論のための複数のハイパーネットワークの使用もサポートします。",
  "Custom Diffusion": "Custom Diffusion",
  "Custom Diffusion is, in short, finetuning-lite with TI, instead of tuning the whole model. Similar speed and memory requirements to TI and supposedly gives better results in less steps.": "カスタムディフュージョンは、要するに、モデル全体をチューニングするのではなく、TIを使ったfinetuning-liteなのです。TIと同様のスピードとメモリが必要ですが、より少ないステップでより良い結果を得られるとされています。",
  "Smart Process": "Smart Process",
  "Smart pre-process including auto subject identification, caption subject swapping, and upscaling/facial restoration.": "自動被写体識別、キャプション被写体入れ替え、アップスケール/顔復元などのスマートプリプロセスを実現。",
  "Embeddings editor": "Embeddings editor",
  "Allows you to manually edit textual inversion embeddings using sliders.": "スライダーを使用してtextual inversionの埋め込みを手動で編集できます。",
  "embedding-inspector": "embedding-inspector",
  "Inspect any token(a word) or Textual-Inversion embeddings and find out which embeddings are similar. You can mix, modify, or create the embeddings in seconds.": "任意のトークン(単語) またはTextual-Inversionの埋め込みを検査し、どの埋め込みが類似しているかを調べることができます。Embeddingsの混合、修正、作成は数秒で可能です。",
  "Merge Board": "Merge Board",
  "Multiple lane merge support(up to 10). Save and Load your merging combination as Recipes, which is simple text.": "複数のレーンマージをサポート(最大10まで) マージの組み合わせはレシピとして保存と読み込みが可能です(テキストのみ)",
  "Model Converter": "Model Converter",
  "Convert models to fp16/bf16 no-ema/ema-only safetensors. Convert/copy/delete any parts of model: unet, text encoder(clip), vae.": "モデルをfp16/bf16 no-ema/ema-only から選択し.safetensor形式に変換します。モデルのいずれかの部分を変換/コピー/削除します: unet, text encoder(clip), vae.",
  "Kohya-ss Additional Networks": "Kohya-ss Additional Networks",
  "Allows the Web UI to use LoRAs (1.X and 2.X) to generate images. Also allows editing .safetensors networks prompt metadata.": "Web UI が LoRA (1.X および 2.X) を使用して画像を生成できます。また、.safetensors ネットワークを編集してメタデータをプロンプトできます。",
  "Merge Block Weighted": "Merge Block Weighted",
  "Merge models with separate rate for each 25 U-Net block (input, middle, output).": "25個のU-Netブロック(入力、中間、出力) ごとに別々の重みを持つモデルをマージします。",
  "Embedding Merge": "Embedding Merge",
  "Merging Textual Inversion embeddings at runtime from string literals. Phrases and weight values also supported.": "Textual Inversion を文字列リテラルから実行時にマージします。フレーズと重みの値もサポートされています。",
  "SuperMerger": "SuperMerger",
  "Merge and run without saving to drive. Sequential XY merge generations; extract and merge loras, bind loras to ckpt, merge block weights, and more.": "ドライブに保存することなく、マージして実行することができます。順次XYマージ生成、LoRAの抽出とマージ、LoRAとckptの結合、階層別のマージ等。一部の操作には大量のRAMとdiffusersが必要です。",
  "LoRA Block Weight": "LoRA Block Weight",
  "Applies LoRA strength; block by block on the fly. Includes presets, weight analysis, randomization, XY plot.": "LoRAの強度を、ブロックごとにオンザフライで適用します。プリセット、重量分析、ランダム化、XYプロットが含まれます。",
  "Image browser": "Image browser",
  "Provides an interface to browse created images in the web browser.": "Webブラウザで作成された画像を閲覧するためのインターフェースを提供します。",
  "Inspiration": "Inspiration",
  "Randomly display the pictures of the artist's or artistic genres typical style, more pictures of this artist or genre is displayed after selecting. So you don't have to worry about how hard it is to choose the right style of art when you create.": "アーティストのジャンルや芸術ジャンルの典型的なスタイルの写真をランダムに表示し、選択した後にそのアーティストやジャンルのより多くの画像が表示されます。 ゆえに、あなたが創作するときに正しいスタイルのアートを選択するのがどれほど難しいか心配する必要はありません。",
  "Artists to study": "Artists to study",
  "Shows a gallery of generated pictures by artists separated into categories.": "カテゴリに分けられたアーティストが生成した画像のギャラリーを表示します。",
  "Prompt Gallery": "Prompt Gallery",
  "Build a yaml file filled with prompts of your character, hit generate, and quickly preview them by their word attributes and modifiers.": "キャラクターのプロンプトを含むyamlファイルを構築し、生成を押すと、単語の属性やモディファイアによって素早くプレビューすることができます。",
  "Infinity Grid Generator": "Infinity Grid Generator",
  "Build a yaml file with your chosen parameters, and generate infinite-dimensional grids. Built-in ability to add description text to fields. See readme for usage details.": "選択したパラメータでyamlファイルを構築し、無限次元グリッドを生成します。フィールドに説明テキストを追加する組み込み機能です。使用方法については、readmeを参照してください。",
  "Config-Presets": "Config-Presets",
  "Adds a configurable dropdown to allow you to change UI preset settings in the txt2img and img2img tabs.": "設定可能なドロップダウンを追加すると、txt2img および img2img タブの UI プリセット設定を変更できます。",
  "Preset Utilities": "Preset Utilities",
  "Preset utility tool for ui. Offers compatibility with custom scripts. (to a limit)": "Web UI用のプリセットユーティリティツール。カスタムスクリプトとの互換性を提供します。(制限付き)",
  "openOutpaint extension": "openOutpaint extension",
  "A tab with the full openOutpaint UI. Run with the --api flag.": "完全な openOutpaint UI を持つタブ。--api フラグを付けて実行します。",
  "quick-css": "quick-css",
  "Extension for quickly selecting and applying custom.css files, for customizing look and placement of elements in ui.": "UI内の要素の外観と配置をカスタマイズするために、custom.cssファイルを迅速に選択して適用するための拡張機能。",
  "Aspect Ratio selector": "Aspect Ratio selector",
  "Adds image aspect ratio selector buttons.": "画像のアスペクト比選択ボタンを追加します。",
  "Catppuccin Theme": "Catppuccin Theme",
  "Adds various custom themes": "様々なカスタムテーマを追加",
  "Kitchen Theme": "Kitchen Theme",
  "Custom Theme.": "カスタムテーマ",
  "Bilingual Localization": "Bilingual Localization",
  "Bilingual translation, no need to worry about how to find the original button. Compatible with language pack extensions, no need to re-import.": "バイリンガル翻訳, 元のボタンを見つける方法を心配する必要はありません. 言語パックの拡張機能と互換性, 再インポートする必要はありません.",
  "Dynamic Prompts": "Dynamic Prompts",
  "Implements an expressive template language for random or combinatorial prompt generation along with features to support deep wildcard directory structures.": "表現力豊かなテンプレート言語を使って、ランダムまたは組み合わせ式のプロンプト生成を実現し、複雑なワイルドカードのディレクトリ構造にも対応できる機能を実装しています。",
  "Unprompted": "Unprompted",
  "Allows you to include various shortcodes in your prompts. You can pull text from files, set up your own variables, process text through conditional functions, and so much more - it's like wildcards on steroids. It now includes integrations like hard-prompts made easy, ControlNet, txt2img2img and txt2mask.": "さまざまなショートコードをプロンプトに含めることができます。 ファイルからテキストを取り出して、独自の変数を設定したり、条件付き関数を通じてテキストを処理したり、またそれ以上のことができます。いわば強化されたワイルドカードのようなものです。これは、hard-prompts made eary、ControlNet、txt2img2imgやtxt2maskの統合機能が含まれています。",
  "StylePile": "StylePile",
  "An easy way to mix and match elements to prompts that affect the style of the result.": "結果のスタイルに影響を与える要素をプロンプトに混ぜてマッチさせる簡単な方法です。",
  "Booru tag autocompletion": "Booru tag autocompletion",
  "Displays autocompletion hints for tags from image booru boards such as Danbooru. Uses local tag CSV files and includes a config for customization.": "Danbooruなどの画像ボードからのタグの自動補完のヒントを表示します。ローカルタグCSVファイルを使用し、カスタマイズのための設定を含みます。",
  "novelai-2-local-prompt": "novelai-2-local-prompt",
  "Add a button to convert the prompts used in NovelAI for use in the WebUI. In addition, add a button that allows you to recall a previously used prompt.": "NovelAI で使用されているプロンプトをWebUI で使用するためのボタンを追加します。 さらに、以前に使用したプロンプトを呼び出すためのボタンを追加します。",
  "tokenizer": "tokenizer",
  "Adds a tab that lets you preview how CLIP model would tokenize your text.": "CLIPモデルがどのようにテキストをトークン化するかをプレビューできるタブを追加します。",
  "Randomize": "Randomize",
  "Allows for random parameters during txt2img generation. This script will function with others as well. Original author: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize": "txt2img 生成中にランダムなパラメータを許可します。このスクリプトは他のものと同様に機能します。オリジナルの作者: https://git.mmaker.moe/mmaker/stable-diffusion-webui-randomize",
  "conditioning-highres-fix": "conditioning-highres-fix",
  "This is Extension for rewriting Inpainting conditioning mask strength value relative to Denoising strength at runtime. This is useful for Inpainting models such as sd-v1-5-inpainting.ckpt": "Inpaintingのコンディショニングマスクの強さをDenoisingの強さに対して実行時に相対的に書き換えるためのExtensionです。sd-v1-5-inpainting.ckptのようなInpaintingモデルで有用です。",
  "model-keyword": "model-keyword",
  "Inserts matching keyword(s) to the prompt automatically. Update this extension to get the latest model+keyword mappings.": "マッチするキーワードを自動的にプロンプトに挿入します。この拡張機能を更新して、最新の model+keyword マッピングを取得します。",
  "Prompt Generator": "Prompt Generator",
  "generate a prompt from a small base prompt using distilgpt2. Adds a tab with additional control of the model.": "distilgpt2 を使用して小さなベースプロンプトからプロンプトを生成します。モデルの追加制御を行うタブを追加します。",
  "Promptgen": "Promptgen",
  "Use transformers models to generate prompts.": "トランスフォーマーモデルを使用してプロンプトを生成します。",
  "text2prompt": "text2prompt",
  "Generates anime tags using databases and models for tokenizing.": "データベースやモデルを使ってアニメのタグを生成し、トークン化する。",
  "Prompt Translator": "Prompt Translator",
  "A integrated translator for translating prompts to English using Deepl or Baidu.": "DeeplやBaiduを使ってプロンプトを英語に翻訳するための統合翻訳機です。",
  "Deforum": "Deforum",
  "The official port of Deforum, an extensive script for 2D and 3D animations, supporting keyframable sequences, dynamic math parameters (even inside the prompts), dynamic masking, depth estimation and warping.": "Deforumの公式ポート, つまり2Dおよび3Dアニメーションのための広範なスクリプトで、 キーフレーム可能なシーケンス、動的数学パラメータ(プロンプト内でも)、動的マスキング、深さ推定、およびワーピングをサポートしています。",
  "Animator": "Animator",
  "A basic img2img script that will dump frames and build a video file. Suitable for creating interesting zoom-in warping movies. This is intended to be a versatile toolset to help you automate some img2img tasks.": "フレームをダンプしてビデオファイルを構築する基本的なimg2imgスクリプト。興味深いズームイン・ワーピングの動画を作成するのに適しています。これは、img2imgのタスクを自動化するための多機能なツールセットであることを意図しています。",
  "gif2gif": "gif2gif",
  "A script for img2img that extract a gif frame by frame for img2img generation and recombine them back into an animated gif": "Img2imgのためにgifをフレーム単位で抽出し、アニメーションgifに組み戻すスクリプトです。",
  "Video Loopback": "Video Loopback",
  "A video2video script that tries to improve on the temporal consistency and flexibility of normal vid2vid.": "通常のvid2vidの時間的整合性と柔軟性を改善しようとするvideo2videoスクリプトです。",
  "seed travel": "seed travel",
  "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.": "Small script for AUTOMATIC1111/stable-diffusion-webui to create images that exists between seeds.",
  "shift-attention": "shift-attention",
  "Generate a sequence of images shifting attention in the prompt. This script enables you to give a range to the weight of tokens in a prompt and then generate a sequence of images stepping from the first one to the second.": "プロンプトの注意をずらす画像のシーケンスを生成する。このスクリプトは、プロンプト内のトークンの重みに範囲を与え、最初のトークンから2番目のトークンへとステップする一連の画像を生成することができます。",
  "prompt travel": "prompt travel",
  "Extension script for AUTOMATIC1111/stable-diffusion-webui to travel between prompts in latent space.": "AUTOMATIC1111/stable-diffusion-webuiの拡張スクリプトは、潜在領域のプロンプト間を移動します。",
  "Steps Animation": "Steps Animation",
  "Create animation sequence from denoised intermediate steps.": "デノイズされた中間ステップからアニメーションシーケンスを作成します。",
  "auto-sd-paint-ext": "auto-sd-paint-ext",
  "Krita Plugin.": "Kritaプラグイン。",
  "Detection Detailer": "Detection Detailer",
  "An object detection and auto-mask extension for Stable Diffusion web UI.": "Stable DiffusionのWeb UI用のオブジェクト検出と自動マスクの拡張機能です。",
  "Batch Face Swap": "Batch Face Swap",
  "Automatically detects faces and replaces them.": "顔を自動で検出し、置き換えることができます。",
  "Depth Maps": "Depth Maps",
  "Depth Maps, Stereo Image, 3D Mesh and Video generator extension.": "深さマップ、ステレオイメージ、3Dメッシュおよびビデオジェネレータ拡張。",
  "multi-subject-render": "multi-subject-render",
  "It is a depth aware extension that can help to create multiple complex subjects on a single image. It generates a background, then multiple foreground subjects, cuts their backgrounds after a depth analysis, paste them onto the background and finally does an img2img for a clean finish.": "1枚の画像に複数の複雑な被写体を作成するのに役立つ、深度を認識する拡張機能です。背景を生成し、次に複数の前景の被写体を生成し、深度解析後に背景をカットして背景に貼り付け、最後にimg2imgできれいに仕上げます。",
  "depthmap2mask": "depthmap2mask",
  "Create masks for img2img based on a depth estimation made by MiDaS.": "MiDSの深度推定に基づいてimg2img用のマスクを作成します。",
  "ABG_extension": "ABG_extension",
  "Automatically remove backgrounds. Uses an onnx model fine-tuned for anime images. Runs on GPU.": "背景を自動で除去します。アニメ画像用に微調整されたonnxモデルを使用します。GPUで動作します。",
  "Pixelization": "Pixelization",
  "Using pre-trained models, produce pixel art out of images in the extras tab.": "事前に学習させたモデルを使って、extrasタブの画像からピクセルアートを作成します。",
  "haku-img": "haku-img",
  "Image utils extension. Allows blending, layering, hue and color adjustments, blurring and sketch effects, and basic pixelization.": "画像拡張機能。ブレンド、レイヤー、色調、色調、スケッチエフェクト、基本的なピクセル化が可能です。",
  "Asymmetric Tiling": "Asymmetric Tiling",
  "An always visible script extension to configure seamless image tiling independently for the X and Y axes.": "シームレスイメージタイリングをX軸とY軸で独立して設定するための常時表示スクリプト拡張機能です。",
  "Latent Mirroring": "Latent Mirroring",
  "Applies mirroring and flips to the latent images to produce anything from subtle balanced compositions to perfect reflections": "微妙なバランスの取れた構成から完璧な反射まで、あらゆるものを作り出すために潜在的な画像にミラーリングとフリップを適用します。",
  "Sonar": "Sonar",
  "Improve the generated image quality, searches for similar (yet even better!) images in the neighborhood of some known image, focuses on single prompt optimization rather than traveling between multiple prompts.": "生成された画像の質を向上させ、(更に質の良い) 同様の画像を近傍の既存画像から探索します。複数プロンプト間の切り替えよりも、単一プロンプトの最適化に焦点を当てています。",
  "Depth Image I/O": "Depth Image I/O",
  "An extension to allow managing custom depth inputs to Stable Diffusion depth2img models.": "Stable Diffusion depth2img モデルへのカスタム深度入力を管理できるようにする拡張機能です。",
  "Ultimate SD Upscale": "Ultimate SD Upscale",
  "More advanced options for SD Upscale, less artifacts than original using higher denoise ratio (0.3-0.5).": "SDアップスケールのためのより進歩したオプション。より高いデノイズ率 (0.3-0.5) を用いてオリジナルよりも少ない歪みを実現します。",
  "Fusion": "Fusion",
  "Adds prompt-travel and shift-attention-like interpolations (see exts), but during/within the sampling steps. Always-on + works w/ existing prompt-editing syntax. Various interpolation modes. See their wiki for more info.": "プロンプトトラベルとshift-attention のような補間(extを参照) を追加します。 Always-on + は既存のプロンプト編集構文で動作します。さまざまな補間モードです。詳細は wiki をご覧ください。",
  "Dynamic Thresholding": "Dynamic Thresholding",
  "Adds customizable dynamic thresholding to allow high CFG Scale values without the burning / 'pop art' effect.": "カスタマイズ可能な動的閾値を追加することで、焼き込みやポップアート効果なしに高いCFG Scale値を可能にします。",
  "anti-burn": "anti-burn",
  "Smoothing generated images by skipping a few very last steps and averaging together some images before them.": "最後の数ステップをスキップし、それ以前のいくつかの画像をまとめて平均化することで生成された画像を平滑化します。",
  "sd-webui-controlnet": "sd-webui-controlnet",
  "WebUI extension for ControlNet. Note: (WIP), so don't expect seed reproducibility - as updates may change things.": "ControlNetのWebUI拡張機能です。注：（作成途中）アップデートによって状況が変わる可能性があるため、シードによる再現性を期待しないでください。",
  "Latent Couple": "Latent Couple",
  "An extension of the built-in Composable Diffusion, allows you to determine the region of the latent space that reflects your subprompts. Note: New maintainer, uninstall prev. ext if needed.": "内蔵のComposable Diffusionを拡張したもので、サブプロンプトを反映した潜像空間の領域を決定することができます。 注: 新しいメンテナーのリポジトリURLに移行したため、必要に応じて古い拡張機能をアンインストールしてください。",
  "Composable LoRA": "Composable LoRA",
  "Enables using AND keyword(composable diffusion) to limit LoRAs to subprompts. Useful when paired with Latent Couple extension.": "ANDキーワード（Composable diffusion）を使って、LoRAをサブプロンプトに限定できるようになります。Latent Couple extensionと組み合わせると便利です。",
  "Auto TLS-HTTPS": "Auto TLS-HTTPS",
  "Allows you to easily, or even completely automatically start using HTTPS.": "簡単に、あるいは完全に自動でHTTPSの使用を開始できるようにします。",
  "booru2prompt": "booru2prompt",
  "This SD extension allows you to turn posts from various image boorus into stable diffusion prompts. It does so by pulling a list of tags down from their API. You can copy-paste in a link to the post you want yourself, or use the built-in search feature to do it all without leaving SD.": "このSD拡張機能により、さまざまな画像の投稿を安定した拡散プロンプトに変換できます。 これは API からタグの一覧を引き出すことで行います。 自分で好きな投稿へのリンクをコピー&ペーストすることも、内蔵の検索機能を使ってSDを離れることなくすべてを行うことも可能です。",
  "Gelbooru Prompt": "Gelbooru Prompt",
  "Extension that gets tags for saved gelbooru images in AUTOMATIC1111's Stable Diffusion webui": "AUTOMATIC1111のStable Diffusion webui上で、gelbooru画像のタグを取得する拡張機能",
  "NSFW checker": "NSFW checker",
  "Replaces NSFW images with black.": "NSFW画像を黒に置き換えます。",
  "Diffusion Defender": "Diffusion Defender",
  "Prompt blacklist, find and replace, for semi-private and public instances.": "セミプライベートやパブリックインスタンスのためのブラックリストプロンプトを検索、置換する機能",
  "DH Patch": "DH Patch",
  "Random patches by D8ahazard. Auto-load config YAML files for v2, 2.1 models; patch latent-diffusion to fix attention on 2.1 models (black boxes without no-half), whatever else I come up with.": "D8ahazardによるランダムパッチ。v2、2.1モデル用の自動ロード設定YAMLファイル; 2.1モデルの注意を修正するための潜在的な拡散パッチ (no-halfなしの黒いボックス) 、それ以外にも思いつく限りのこと。",
  "Riffusion": "Riffusion",
  "Use Riffusion model to produce music in gradio. To replicate original interpolation technique, input the prompt travel extension output frames into the riffusion tab.": "Riffusionモデルを使用して、gradioで音楽を生成します。元の補間技術を再現するには、プロンプトのトラベルエクステンション出力フレームをRiffusionタブに入力してください。",
  "Save Intermediate Images": "Save Intermediate Images",
  "Save intermediate images during the sampling process. You can also make videos from the intermediate images.": "サンプリング処理中に中間画像を保存し、中間画像から動画を作成することも可能です。",
  "Add image number to grid": "Add image number to grid",
  "Add the image's number to its picture in the grid.": "グリッド内の画像に画像の番号を追加",
  "Multiple Hypernetworks": "Multiple Hypernetworks",
  "Adds the ability to apply multiple hypernetworks at once. Apply multiple hypernetworks sequentially, with different weights.": "複数のハイパーネットワークを一度に適用する機能を追加します。異なる重みで複数のハイパーネットワークを連続的に適用します。",
  "System Info": "System Info",
  "System Info tab for WebUI which shows realtime information of the server. Also supports sending crowdsourced inference data as an option.": "サーバーのリアルタイム情報を表示するWebUIのシステム情報タブ。オプションとしてクラウドソースの推論データを送信することもできます。",
  "OpenPose Editor": "OpenPose Editor",
  "This can add multiple pose characters, detect pose from image, save to PNG, and send to controlnet extension.": "複数のポーズキャラクターを追加したり、画像からポーズを検出しPNGに保存したり、controlnetの拡張機能に送信することができます。",
  "Stable Horde Worker": "Stable Horde Worker",
  "Worker Client for Stable Horde. Generate pictures for other users with your PC. Please see readme for additional instructions.": "Stable Horde用のワーカークライアント。あなたのPCで、他のユーザーのために写真を生成します。その他の説明はreadmeをご覧ください。",
  "Stable Horde Client": "Stable Horde Client",
  "Stable Horde Client. Generate pictures using other user's PC. Useful if u have no GPU.": "Stable Horde Client. 他のユーザーのPCを使用して画像を生成します。GPUがない場合に便利です。",
  "Discord Rich Presence": "Discord Rich Presence",
  "Provides connection to Discord RPC, showing a fancy table in the user profile.": "Discord RPCへの接続を提供し、ユーザープロファイルにファンシーテーブルを表示します。",
  "mine-diffusion": "mine-diffusion",
  "This extension converts images into blocks and creates schematics for easy importing into Minecraft using the Litematica mod.": "この拡張機能は画像をブロックに変換し、Litematica modを使用してMinecraftに簡単にインポートできる回路図を作成します。",
  "Aesthetic Image Scorer": "Aesthetic Image Scorer",
  "Calculates aesthetic score for generated images using CLIP+MLP Aesthetic Score Predictor based on Chad Scorer": "Chad Scorerに基づくClip+MLP審美的スコア予測器を使用して、生成された画像の審美的スコアを計算する。",
  "Aesthetic Scorer": "Aesthetic Scorer",
  "Uses existing CLiP model with an additional small pretrained model to calculate perceived aesthetic score of an image.": "既存のCLiPモデルに、事前に学習させた小さなモデルを追加して、画像の知覚的な美的スコアを算出します。",
  "cafe-aesthetic": "cafe-aesthetic",
  "Pre-trained model, determines if aesthetic/non-aesthetic, does 5 different style recognition modes, and Waifu confirmation. Also has a tab with Batch processing.": "事前に学習させたモデルで、美的／非美的の判定、5種類のスタイル認識モード、Waifu確認ができます。また、バッチ処理のタブもあります。",
  "Clip Interrogator": "Clip Interrogator",
  "Clip Interrogator by pharmapsychotic ported to an extension. Features a variety of clip models and interrogate settings.": "「Pharmapsychotic」による「Clip Interrogator」が拡張機能に移植されました。さまざまなクリップモデルと問い合わせ設定を備えています。",
  "Visualize Cross-Attention": "Visualize Cross-Attention",
  "Generates highlighted sectors of a submitted input image, based on input prompts. Use with tokenizer extension. See the readme for more info.": "入力プロンプトに基づき、送信された入力画像のハイライト部分を生成する。トークナイザーエクステンションと組み合わせて使用します。詳しくはReadmeをご覧ください。",
  "DAAM": "DAAM",
  "DAAM stands for Diffusion Attentive Attribution Maps. Enter the attention text (must be a string contained in the prompt) and run. An overlapping image with a heatmap for each attention will be generated along with the original image.": "DAAMはDiffusion Attentive Attentive Attentive Mapsの略です。注意テキスト(プロンプトに含まれている文字列である必要があります) を入力して実行します。 注目テキストごとに、ヒートマップを重ねた画像が元の画像とともに生成されます。",
  "Dump U-Net": "Dump U-Net",
  "View different layers, observe U-Net feature maps. Image generation by giving different prompts for each block of the unet: https://note.com/kohya_ss/n/n93b7c01b0547": "異なるレイヤーを表示し、U-Netの特徴マップを観察します。各ブロックに異なるプロンプトを与えることで画像を生成します。: https://note.com/kohya_ss/n/n93b7c01b0547",
  "posex": "posex",
  "Estimated Image Generator for Pose2Image. This extension allows moving the openpose figure in 3d space.": "Pose2Image用の推定画像生成ツールです。この拡張機能により、openposeのフィギュアを3D空間で動かすことができます。",
  "LLuL": "LLuL",
  "Local Latent Upscaler. Target an area to selectively enhance details.": "Local Latent Upscaler（ローカル・ラテント・アップスケーラー）。領域を指定して、選択的にディテールを強調することができます。",
  "CFG-Schedule-for-Automatic1111-SD": "CFG-Schedule-for-Automatic1111-SD",
  "These scripts allow for dynamic CFG control during generation steps. With the right settings, this could help get the details of high CFG without damaging the generated image even with low denoising in img2img.": "これらのスクリプトは、生成ステップ中の動的なCFG制御を可能にします。適切な設定により、img2imgでノイズ除去が少ない場合でも、生成された画像にダメージを与えることなく、高CFGの詳細を得ることができる可能性があります。",
  "a1111-sd-webui-locon": "a1111-sd-webui-locon",
  "loading LoCon/LyCoris networks in webui. NOTE: depreciated in favor of https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris, due to error with with other lora ext.": "loading LoCon/LyCoris networks in webui. NOTE: depreciated in favor of https://github.com/KohakuBlueleaf/a1111-sd-webui-lycoris, due to error with with other lora ext.",
  "ebsynth_utility": "ebsynth_utility",
  "Extension for creating videos using img2img and ebsynth. Output edited videos using ebsynth. Works with ControlNet extension.": "Img2imgとebsynthを使用して動画を作成するための拡張。ebsynthを使用して動画を出力します。ControlNet拡張機能で動作します。",
  "VRAM Estimator": "VRAM Estimator",
  "Runs txt2img, img2img, highres-fix at increasing dimensions and batch sizes until OOM, and outputs data to graph.": "Txt2img、img2img、highres-fixを、次元とバッチサイズを増やしてOOMまで実行し、データをグラフに出力する。",
  "MultiDiffusion with Tiled VAE": "MultiDiffusion with Tiled VAE",
  "Seamless Image Fusion, along with vram efficient tiled vae script.": "シームレスな画像融合、Vram効率の良いタイル状のVAEスクリプトと共に",
  "3D Model&Pose Loader": "3D Model&Pose Loader",
  "Load your 3D model/animation inside webui, or edit model pose as well, then send screenshot to txt2img or img2img to ControlNet.": "web UI内に3Dモデル/アニメーションを読み込んだり、モデルのポーズを編集して、スクリーンショットをControlNet用にtxt2imgまたはimg2imgに送信できます。",
  "Corridor Crawler Outpainting": "Corridor Crawler Outpainting",
  "Generate hallways with the depth-to-image model at 512 resolution. It can be tweaked to work with other models/resolutions.": "解像度512の深度画像モデルで廊下を生成します。他のモデル/解像度で動作するように調整することができます。",
  "Panorama Viewer": "Panorama Viewer",
  "Provides a tab to display equirectangular images in interactive 3d-view.": "エクイレクタングラー形式の画像をインタラクティブな3dビューで表示するタブを提供します。",
  "db-storage1111": "db-storage1111",
  "Allows to store pictures and their metadata in a database. (supports MongoDB)": "画像とそのメタデータをデータベースに保存できます。(MongoDBをサポート)",
  "stable-diffusion-webui-rembg": "stable-diffusion-webui-rembg",
  "Removes backgrounds from pictures.": "画像から背景を削除します。",
  "sd-webui-tunnels": "sd-webui-tunnels",
  "Add alternatives to the default tunneling methods. (including cloudflared)": "デフォルトのトンネリングメソッドに代わるものを追加します(Cloudflaredを含む)。",
  "3D Openpose Editor": "3D Openpose Editor",
  "Edit the pose of 3D models in the WebUI, and generate Openpose/Depth/Normal/Canny maps for ControlNet.": "WebUIで3Dモデルのポーズを編集し、ControlNet用のOpenpose/Depth/Normal/Cannyマップを生成します。",
  "sd-webui-enable-checker": "sd-webui-enable-checker",
  "Switch background color by clicking the Enable buttons in SD Web UI": "SD Web UIの「有効化」ボタンをクリックして背景色を切り替える",
  "stable-diffusion-webui-state": "stable-diffusion-webui-state",
  "Preserves the UI state after reload/restart.": "リロード/再起動後にUI状態を保持します。",
  "text2video": "text2video",
  "Implementation of text2video diffusion models, such as ModelScope or VideoCrafter, using only Auto1111 webui dependencies.": "ModelScopeやVideoCrafterなどのtext2video拡散モデルの実装では、Auto1111 webuiの依存関係のみを使用しています。",
  "Aspect Ratio Helper": "Aspect Ratio Helper",
  "Easily scale dimensions while retaining the same aspect ratio.": "同じアスペクト比を維持しながら簡単に拡大できます。",
  "Canvas Zoom": "Canvas Zoom",
  "Added the ability to scale Inpaint, Sketch, and Inpaint Sketch. Adds useful hotkeys": "Inpaint、スケッチ、Inpaintスケッチをスケール(拡大縮小)する機能を追加しました。便利なショートカットキーを追加します。",
  "Regional Prompter": "Regional Prompter",
  "Specify different prompts for different regions; an alternative method and potential improvement to latent couple.": "異なる領域に異なるプロンプトを指定します。Latent Coupleに代わる方法であり、改善の可能性があります。",
  "Auto Translate": "Auto Translate",
  "Language extension allows users to write prompts in their native language and automatically translate UI, without the need to manually download configuration files. New plugins can also be translated.": "言語の拡張機能により、設定ファイルを手動でダウンロードすることなく、母国語でプロンプトを記述し、UIを自動的に翻訳することができます。新しいプラグインも翻訳できます。",
  "Allows users to generate images based on prompts written in 50 different languages. It translates the prompts to english from a selected source language before generating the image.": "50 種類の言語で書かれたプロンプトをもとに、画像を生成できます。 画像を生成する前に、選択した元の言語から英語にプロンプトを翻訳します。",
  "Abysz LAB": "Abysz LAB",
  "Temporal Coherence Tools": "時間的な一貫性ツール",
  "Negative Prompt Weight": "Negative Prompt Weight",
  "Allows users to set a global weight for the negative prompt.": "ネガティブプロンプト全体の重みを設定できるようにします。",
  "Discord - Dynamic Rich Presence": "Discord - Dynamic Rich Presence",
  "Will show your current sd model selected. Also showing if you are idle, or generating something - in that case, total image/s being generated.": "ステータスに、現在選択されているsdのモデルが表示されます。また、アイドル状態であるか、何かを生成しているか（その場合、秒あたりの生成枚数）も表示されます。",
  "PBRemTools": "PBRemTools",
  "PBRemTools(Precise background remover tools) is a collection of tools to crop backgrounds from a single picture with high accuracy.": "PBRemTools(正確な背景除去ツール)は、1枚の写真から背景を高精度に切り抜くためのツール集です。",
  "a1111-sd-webui-lycoris": "a1111-sd-webui-lycoris",
  "Load lycoris: non-conventional rank adapters; in separate networks gallery tab.": "Load lycoris: non-conventional rank adapters; in separate networks gallery tab.",
  "zh_CN Localization": "zh_CN Localization",
  "Simplified Chinese localization, recommend using with Bilingual Localization.": "簡易版中国語ローカライゼーション。バイリンガルローカライゼーションと併せて使用することを推奨します。",
  "zh_TW Localization": "zh_TW Localization",
  "Traditional Chinese localization": "中国語繁体字翻訳",
  "ko_KR Localization": "ko_KR Localization",
  "Korean localization": "韓国語翻訳",
  "th_TH Localization": "th_TH Localization",
  "Thai localization": "タイ語翻訳",
  "es_ES Localization": "es_ES Localization",
  "Spanish localization": "スペイン語翻訳",
  "it_IT Localization": "it_IT Localization",
  "Italian localization": "イタリア語翻訳",
  "de_DE Localization": "de_DE Localization",
  "German localization": "ドイツ語翻訳",
  "ja_JP Localization": "ja_JP Localization",
  "Japanese localization": "日本語翻訳",
  "pt_BR Localization": "pt_BR Localization",
  "Brazillian portuguese localization": "ブラジル・ポルトガル語翻訳",
  "tr_TR Localization": "tr_TR Localization",
  "Turkish localization": "トルコ語翻訳",
  "no_NO Localization": "no_NO 翻訳",
  "Norwegian localization": "ノルウェー語翻訳",
  "ru_RU Localization": "ru_RU Localization",
  "Russian localization": "ロシア語翻訳",
  "fi_FI Localization": "fi_FI Localization",
  "Finnish localization": "フィンランド語翻訳",
  "zh_Hans Localization": "zh_Hans Localization",
  "Simplified Chinese localization.": "簡体字中国語の翻訳",
  "old localizations": "old localizations",
  "Old unmaintained localizations that used to be a part of main repository": "メインリポジトリの一部だった古いメンテナンスされていない翻訳"
}