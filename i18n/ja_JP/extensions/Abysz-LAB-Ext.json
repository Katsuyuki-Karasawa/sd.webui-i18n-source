{
  "Abysz LAB": "Abysz LAB",
  "Main": "メイン",
  "LAB Tools": "LABツール",
  "Guide": "ガイド",
  "Abysz LAB 0.1.9 Temporal coherence tools": "Abysz LAB 0.1.9 時間的な一貫性ツール",
  "DFI Render": "DFIレンダー (Differential frame interpolation - 差分フレーム補完)",
  "Original frames folder": "オリジナルフレームフォルダ",
  "Generated frames folder": "生成したフレームフォルダ",
  "Output folder": "出力先フォルダ",
  "Info": "情報",
  "The new algorithm will adapt to DFI tolerance to choose the parameters for each frame. IMPORTANT: The algorithm is optimized to maintain a balance between deflicking and corruption, so that it is easier to use StableDiffusion at low denoising to reconstruct lost detail while preserving the stability gained.": "新しいアルゴリズムは、各フレームのパラメータを選択するために、DFIの許容範囲に適応します。重要：アルゴリズムは、デフリックとコラプションのバランスを保つように最適化されており、低ノイズ化でStableDiffusionを使用すると、得られた安定性を維持しながら失われたディテールを再構築することが容易になる。",
  "Source denoise:": "ソースデノイズ：",
  "A noisy source can interfere with the accuracy of the scan. This will reduce noise, but also detail. However, this does not affect the original, and sometimes flatter images are not bad for the process, although you may need to balance by reducing the DFI tolerance.": "ノイズの多いソースは、スキャンの精度を妨げる可能性があります。この場合、ノイズは減少しますが、ディテールも減少します。しかし、これはオリジナルには影響しませんし、DFIの許容範囲を狭めることでバランスを取る必要があるかもしれませんが、時には平坦な画像もプロセス上悪いことではありません。",
  "(This is a demanding algorithm)": "(これは要求の高いアルゴリズムです)",
  "DFI Tolerance:": "許容範囲:",
  "Determines the movement tolerance of the scan. Low tolerance will detect even small changes in static areas. High values will detect less movements. Ideally, it should detect the movements that are important to you, and skip the static and useless areas, reducing the flick in those.": "スキャンの移動許容度を決定します。許容範囲が低いと、静止している部分の小さな変化も検知してしまいます。高い値では、より少ない動きを検出します。理想的には、重要な動きを検出し、静的な部分や無駄な部分をスキップして、それらのフリックを減らすことです。",
  "This parameter commands the new dynamic algorithm.": "このパラメータは、新しいダイナミックアルゴリズムを指令します。",
  "DFI Expand:": "DFI Expand:",
  "DFI expand fattens the edges of the areas detected by DFI. Note: DFI tolerance modifies the amount of movement detected. This only affects that result, be it big or small. Its a complementary parameter. 0=Off.": "DFIエクスパンドは、DFIで検出された部分のエッジを太くする。注）DFIトレランスは、検出された動きの量を修正します。これは、結果の大小にかかわらず、その結果にのみ影響します。補完的なパラメーターです。0=オフ。",
  "Source Denoise": "ソースデノイズ：",
  "DFI Tolerance": "許容範囲",
  "DFI Expand": "DFI Expand",
  "Here you can check examples of the motion map for those parameters. It is useful, for example, to adjust denoise if you see that it detects unnecessary graininess. Keep in mind that what you see represents movement between two frames.": "ここでは、それらのパラメータに対するモーションマップの例を確認することができます。例えば、不要な粒状性を検出した場合、ノイズを調整するのに有効です。あくまで2フレーム間の動きであることを意識してください。",
  "The black is basically what it won't process (it will let it through to preserve the movement), and the white what it will try to keep stable in that frame interpolation. Try freely. Here you can also test how the manual smooth works (advanced section).": "黒は基本的にそれが処理しないものです(それは動きを維持するためにそれを介してさせます)。 白色はフレーム補間の中で安定しようとしています ここでは、手動のスムーズな動作(高度なセクション) をテストすることもできます。",
  "Preview DFI Map": "マッププレビュー",
  "Preview amount. 0 = Quick shoot": "Preview amount. 0 = Quick shoot",
  "Advanced": "高度な設定",
  "Inter Denoise:": "Inter Denoise:",
  "Reduces render pixelation generated by corruption. However, be careful. It's resource hungry, and might remove excess detail. Not recommended to change size or FPD, but to use Stable Diffusion to remove the pixelation later.": "破損によって発生するレンダリングピクセレーションを軽減します。ただし、注意が必要です。リソースを消費し、過剰なディテールを削除する可能性があります。サイズやFPDを変更することは推奨されませんが、Stable Diffusionを使用して後でピクセレーションを除去することをお勧めします。",
  "Inter Blur:": "インターブラーです：",
  "Fine tunes the dynamic blur algorithm for DFI map. Lower = Stronger blur effects. Between 2-3 recommended.": "DFIマップのダイナミックブラーアルゴリズムを微調整します。低い＝ブラー効果が強くなる。2-3の間を推奨します。",
  "Corruption Refresh:": "破損の更新:",
  "To reduce the distortion generated by the process, you can recover original information every X number of frames. Lower number = faster refresh.": "処理によって発生する歪みを軽減するために、Xフレームごとにオリジナル情報を復元することができます。数字が小さいほどリフレッシュが速い。",
  "Corruption Preserve:": "破損の保護",
  "Here you decide how much corruption keep in each corruption refresh. Low values will recover more of the original frame, with its changes and flickering, in exchange for reducing corruption. You must find the balance that works best for your goal.": "ここでは、各破損のリフレッシュでどの程度破損を維持するかを決定します。低い値は、破損を減らす代わりに、変化やちらつきのある元のフレームをより多く回復します。目的に応じて最適なバランスを見つける必要があります。",
  "Smooth:": "滑らかに：",
  "This smoothes the edges of the interpolated areas. Low values are currently recommended until the algorithm is updated.": "これにより、補間領域のエッジが滑らかになります。アルゴリズムが更新されるまでは、低い値を推奨します。",
  "Inter Denoise": "ノイズ除去",
  "Inter Denoise Size": "サイズにおけるノイズ除去",
  "Inter Denoise FPD": "FPDにおけるノイズ除去",
  "Inter Blur": "ぼかし",
  "The new dynamic algorithm will handle these parameters. Activate them only for manual control.": "新しいダイナミックアルゴリズムがこれらのパラメータを処理します。手動制御の場合のみ、これらを有効にします。",
  "Corruption Refresh (Lower = Faster)": "破損の更新（低いほど速い）",
  "Corruption Preserve": "破損の保護",
  "Smooth": "スムーズ",
  "Frames to render. 0=ALL": "レンダリングするフレーム数：0=ALL",
  "Run DFI": "DFI を実行します",
  "Status": "ステータス",
  "Show output folder video": "出力フォルダの動画を表示する",
  "|": "|",
  "Deflickers Playground": "フリッカー除去",
  "Frames folder": "フレームフォルダ",
  "I made this series of deflickers based on the standard that Vegas Pro includes. You can use them together or separately. Be careful when mixing them.": "AMD Vegas Proが搭載している規格をベースに作ったフリッカー除去です。一緒に使ってもいいし、別々に使ってもいい。混ぜるときは注意してください。",
  "Blend:": "ブレンドする：",
  "Blends a percentage between frames. This can soften transitions and highlights. 50 is half of each frame. 80 or 20 are recommended values.": "フレーム間を一定割合でブレンドします。これにより、トランジションやハイライトを柔らかくすることができます。50は各フレームの半分です。80または20が推奨値です。",
  "Overlay:": "オーバーレイ：",
  "Use the overlay image blending mode. Note that it works particularly good at mid-high values, wich will modify the overall contrast. You will have to decide what works for you.": "オーバーレイ画像の混合モードを使用します。このモードは、特に中高値で効果を発揮し、全体的なコントラストが変化することに注意してください。何が効果的かは、ご自身でお決めください。",
  "Normalize:": "ノーマライズする：",
  "Calculates the average between frames to merge them. It may be more practical if you don't have a specific Blend deflicker value in mind.": "フレーム間の平均を計算し、それらを統合します。混合時フリッカー除去の値を特に決めていない場合は、こちらの方が実用的かもしれません。",
  "BLEND (0=Off)": "BLEND （0＝オフ）",
  "OVERLAY (0=Off)": "オーバーレイ（0＝オフ）",
  "NORMALIZE (0=Off))": "ノーマライズ(0=OFF)",
  "Deflickers": "フリッカー除去",
  "Style Fuse": "スタイルヒューズ",
  "With this you can merge two sets of frames with overlay technique. For example, you can take a style video that is just lights and/or colors, and overlay it on top of another video.": "これを使えば、オーバーレイ技術で2組のフレームを統合することができます。例えば、光や色だけのスタイルビデオを、別のビデオの上にオーバーレイすることができます。",
  "The resulting video will be useful for use in Img2Img Batch and that the AI render preserves these added color and lighting details, along with the details of the original video.": "出来上がった動画はImg2Img Batchで使用するのに便利で、AIレンダリングでは、元の動画の詳細とともに、これらの追加された色や照明の詳細が保持されることです。",
  "Style frames": "スタイルフレーム",
  "Video frames": "動画フレーム",
  "Fuse Strength": "ヒューズの強さ",
  "Fuse": "ヒューズ",
  "Video extract": "ビデオの抽出",
  "Video path": "深度の動画",
  "Fps. 0=Original": "FPs. 0=オリジナル",
  "Extract": "抽出",
  "What DFI does?": "DFIは何をやっているのか？",
  "DFI processing analyzes the motion of the original video, and attempts to force that information into the generated video. Demo on https://github.com/AbyszOne/Abysz-LAB-Ext": "DFI処理では、元映像の動きを解析し、その情報を強制的に生成映像に反映させることを試みます。\"https://github.com/AbyszOne/Abysz-LAB-Ext\"でデモを実施。",
  "In short, this will reduce flicker in areas of the video that don't need to change, but SD does. For example, for a man smoking, leaning against a pole, it will detect that the pole is static, and will try to prevent it from changing as much as possible.": "要するに、映像の中で変化する必要のない部分のフリッカーを抑えるということです。例えば、電柱に寄りかかってタバコを吸う男性の場合、電柱が静止していることを検知して、なるべく変化しないようにするのです。",
  "This is an aggressive process that requires a lot of control for each context. Read the recommended strategies.": "それぞれの文脈に応じたコントロールが必要な、積極的なプロセスです。推奨される方法をお読みください。",
  "Although Video to Video is the most efficient way, a DFI One Shot method is under experimental development as well.": "Video to Videoが最も効率的な方法ですが、DFI One Shot方式も実験的に開発中です。",
  "Usage strategies": "使用方法",
  "If you get enough understanding of the tool, you can achieve a much more stable and clean enough rendering. However, this is quite demanding.": "このツールを十分に理解すれば、より安定した、きれいなレンダリングを十分に実現することができます。ただし、これはかなり要求性が高い。",
  "Instead, a much friendlier and faster way to use this tool is as an intermediate step. For this, you can allow a reasonable degree of corruption in exchange for more general stability.": "その代わりに、このツールをより友好的かつ迅速に使用する方法は、中間段階として使用することです。この場合、より一般的な安定性と引き換えに、適度な破損を許容することができます。",
  "You can then clean up the corruption and recover details with a second step in Stable Diffusion at low denoising (0.2-0.4), using the same parameters and seed.": "その後、同じパラメータとシード値を使用して、低ノイズ化（0.2-0.4）で安定された拡散の第2ステップで破損をクリーンアップし、詳細を回復することができます。",
  "In this way, the final result will have the stability that we have gained, maintaining final detail. If you find a balanced workflow, you will get something at least much more coherent and stable than the raw AI render.": "こうすることで、最終的なディテールを維持したまま、得た安定性を最終結果に反映させることができる。バランスの取れたワークフローを見つけられれば、少なくとも生のAIレンダーよりもずっとまとまりのある安定したものが得られるはずです。",
  "Abysz-LAB-Ext": "Abysz-LAB-Ext",
  "https://github.com/AbyszOne/Abysz-LAB-Ext": "https://github.com/AbyszOne/Abysz-LAB-Ext",
  "The RAW frames you have used as base for IA generation.": "IA世代のベースとして使用したRAWフレーム。",
  "The frames of AI generated video": "AIが生成した映像のフレーム",
  "Remember that each generation overwrites previous frames in the same folder.": "各世代は、同じフォルダー内の以前のフレームを上書きすることを忘れないでください。",
  "STAND BY...": "スタンバイ...",
  "Frames to process": "処理するフレーム数",
  "Processed frames": "加工済みフレーム",
  "Style to fuse": "融合させるスタイル",
  "Remember to use same fps as generated video for DFI": "DFIで生成されたビデオと同じfpsを使用することを忘れないでください。"
}
